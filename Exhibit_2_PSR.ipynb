{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8156ae07-735f-4ffd-a286-8646dcd556dd",
   "metadata": {},
   "source": [
    "# Precision and Recall of PSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import stats\n",
    "from functions import generate_non_gaussian_data, generate_autocorrelated_non_gaussian_data, sharpe_ratio_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPS = 10_000\n",
    "T = 252*5                       # 5y daily\n",
    "SR0_annual_list = [0.0, 0.5, 1., 1.5, 2.]\n",
    "SR0_list = [s/np.sqrt(252) for s in SR0_annual_list]\n",
    "RSEED = 2025\n",
    "# Mixture configs: (name, p_tail, mu_tail, sigma_tail, sigma_core)\n",
    "configs = [\n",
    "    (\"gaussian\", 0.00, 0.00, 0.010, 0.010),\n",
    "    (\"mild\",     0.04, -0.03, 0.015, 0.010),\n",
    "    (\"moderate\", 0.03, -0.045, 0.020, 0.010),\n",
    "    (\"severe\",   0.02, -0.060, 0.025, 0.010),\n",
    "]\n",
    "\n",
    "RHOs = [0, .2]\n",
    "\n",
    "def mixture_variance(p_tail, mu_tail, sigma_tail, mu_core, sigma_core):\n",
    "    w = 1.0 - p_tail\n",
    "    mu = w*mu_core + p_tail*mu_tail\n",
    "    m2 = w*(sigma_core**2 + mu_core**2) + p_tail*(sigma_tail**2 + mu_tail**2)\n",
    "    return m2 - mu**2\n",
    "\n",
    "def gen_with_true_SR0(reps, T, cfg, SR0, seed):\n",
    "    name, p, mu_tail, sig_tail, sig_core = cfg\n",
    "    # Zero-mean baseline mixture (choose mu_core so mean=0)\n",
    "    mu_core0 = - p*mu_tail/(1.0 - p)\n",
    "    std0 = np.sqrt(mixture_variance(p, mu_tail, sig_tail, mu_core0, sig_core))\n",
    "    mu_shift = SR0 * std0  # sets population Sharpe to SR0, preserves skew/kurt\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mask = rng.random((reps, T)) < p\n",
    "    X = rng.normal(mu_core0 + mu_shift, sig_core, size=(reps, T))\n",
    "    X[mask] = rng.normal(mu_tail + mu_shift, sig_tail, size=mask.sum())\n",
    "    return X\n",
    "\n",
    "def psr_z_T(X, SR0):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    skew = stats.skew(X, axis=1, bias=False)\n",
    "    kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "    den = np.sqrt((1.0/Tn) * (1.0 - skew*SR0 + ((kappa-1.0)/4.0)*(SR0**2)))\n",
    "    return (sr_hat - SR0)/den\n",
    "\n",
    "def t_stat(X, SR0):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    skew = 0\n",
    "    kappa = 3.0\n",
    "    den = np.sqrt((1.0/Tn) * (1.0 - skew*SR0 + ((kappa-1.0)/4.0)*(SR0**2)))\n",
    "    return (sr_hat - SR0)/den    \n",
    "\n",
    "def my_psr_z_T(X, SR0, rho):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    skew = stats.skew(X, axis=1, bias=False)\n",
    "    kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "    v = sharpe_ratio_variance( SR0, Tn, gamma3=skew, gamma4=kappa, rho=rho, K=1 )\n",
    "    den = np.sqrt(v)\n",
    "    return (sr_hat - SR0)/den\n",
    "\n",
    "if False: \n",
    "    print( psr_z_T(X, SR0) )\n",
    "    print( my_psr_z_T(X, SR0, 0) )  # Same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0160de-0e76-4320-809b-5a7cb0a4bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SR0 = 0, SR1 âˆˆ {0.5, 1.0, 1.5, 2.0}\n",
    "\n",
    "SR0_annual = 0.0\n",
    "SR0_daily  = 0.0\n",
    "SR1_annual_list = [0.5, 1.0, 1.5, 2.0]\n",
    "SR1_daily_list  = [s/np.sqrt(252) for s in SR1_annual_list]\n",
    "\n",
    "SR1_daily_list = [ .15, .30, .45, .60 ]\n",
    "T = 12 * 5\n",
    "\n",
    "def _confusion_metrics(y_true, pvals, alpha=0.05):\n",
    "    yhat = (pvals < alpha)\n",
    "    TP = int(((y_true==1)&(yhat)).sum())\n",
    "    FP = int(((y_true==0)&(yhat)).sum())\n",
    "    TN = int(((y_true==0)&(~yhat)).sum())\n",
    "    FN = int(((y_true==1)&(~yhat)).sum())\n",
    "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
    "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
    "    f1   = (2*prec*rec)/(prec+rec) if (prec>0 and rec>0) else (0.0 if (prec==0 or rec==0) else np.nan)\n",
    "    return prec, rec, f1\n",
    "\n",
    "rows = []\n",
    "for cfg in configs:\n",
    "    for SR1_daily, SR1_annual in zip(SR1_daily_list, SR1_annual_list):\n",
    "        # Null: SR = 0 ; Alternative: SR = SR1 (annual)\n",
    "        X0 = gen_with_true_SR0(REPS, T, cfg, SR0=SR0_daily, seed=RSEED)\n",
    "        X1 = gen_with_true_SR0(REPS, T, cfg, SR0=SR1_daily, seed=RSEED+1)\n",
    "        y_true = np.r_[np.zeros(len(X0), dtype=int), np.ones(len(X1), dtype=int)]\n",
    "\n",
    "        X = np.concatenate( [X0, X1], axis = 1 )\n",
    "        skew = stats.skew(X, axis=1, bias=False)\n",
    "        kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "\n",
    "        # PSR one-sided test (H1: SR > 0)\n",
    "        p_psr = np.r_[stats.norm.sf(psr_z_T(X0, SR0_daily)),\n",
    "                      stats.norm.sf(psr_z_T(X1, SR0_daily))]\n",
    "        prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "\n",
    "        rows.append({\n",
    "            \"config\": cfg[0],\n",
    "            \"SR1\": SR1_daily,\n",
    "            'gamma3': skew.mean(),\n",
    "            'gamma4': kappa.mean(),\n",
    "            #\"SR1_annual\": SR1_annual,\n",
    "            \"PSR_precision\": prec,\n",
    "            \"PSR_recall\": rec,\n",
    "            \"PSR_F1\": f1\n",
    "        })\n",
    "\n",
    "psr_table = pd.DataFrame(rows).sort_values(\n",
    "    [\"config\",\"SR1\"]\n",
    ").set_index([\"config\",\"SR1\"]).round(4)\n",
    "psr_table.to_csv('appendix_2.csv')\n",
    "psr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f2(rho, name, SR0_daily, SR1_daily):\n",
    "    # Null: SR = 0 ; Alternative: SR = SR1 (annual)\n",
    "    if rho == 0:\n",
    "        X0 = generate_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name )\n",
    "        X1 = generate_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name )\n",
    "    else:\n",
    "        X0 = generate_autocorrelated_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name, rho = rho )\n",
    "        X1 = generate_autocorrelated_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name, rho = rho )\n",
    "            \n",
    "    y_true = np.r_[np.zeros(REPS, dtype=int), np.ones(REPS, dtype=int)]\n",
    "\n",
    "    X = np.concatenate( [X0, X1], axis = 1 )\n",
    "    skew = stats.skew(X, axis=1, bias=False)\n",
    "    kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "\n",
    "\n",
    "    # PSR one-sided test (H1: SR > 0)\n",
    "    p_psr = np.r_[\n",
    "        stats.norm.sf(my_psr_z_T(X0.T, SR0_daily, rho)),\n",
    "        stats.norm.sf(my_psr_z_T(X1.T, SR0_daily, rho)),\n",
    "    ]\n",
    "    prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"rho\": rho, \n",
    "        'gamma3': skew.mean(),\n",
    "        'gamma4': kappa.mean(),\n",
    "        \"SR1\": SR1_daily,\n",
    "        \"PSR_precision\": prec,\n",
    "        \"PSR_recall\": rec,\n",
    "        \"PSR_F1\": f1\n",
    "    }\n",
    "\n",
    "rows = [\n",
    "    f2.remote(rho, name, SR0_daily, SR1_daily)\n",
    "    for rho in RHOs\n",
    "    for name in ['gaussian', 'mild', 'moderate', 'severe']\n",
    "    for SR1_daily in SR1_daily_list\n",
    "]\n",
    "rows = [ ray.get(r) for r in tqdm(rows) ]\n",
    "rows = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "        \n",
    "    rho = 0\n",
    "    name = \"gaussian\"\n",
    "    SR0_daily = 0\n",
    "    SR1_daily = SR1_daily_list[1]\n",
    "    SR1_annual = SR1_annual_list[1]\n",
    "\n",
    "    X0 = generate_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name )\n",
    "    X1 = generate_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name )\n",
    "        \n",
    "    y_true = np.r_[np.zeros(REPS, dtype=int), np.ones(REPS, dtype=int)]\n",
    "\n",
    "    p_psr = np.r_[\n",
    "        stats.norm.sf(my_psr_z_T(X0.T, SR0_daily, rho)),\n",
    "        stats.norm.sf(my_psr_z_T(X1.T, SR0_daily, rho)),\n",
    "    ]\n",
    "    prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "    rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psr_table = pd.DataFrame(rows).sort_values(\n",
    "    [\"name\",\"rho\",\"SR1\"]\n",
    ")\n",
    "psr_table.to_csv('exhibit_2.csv', index = False)\n",
    "psr_table.set_index([\"name\",\"rho\",\"SR1\"]).round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
