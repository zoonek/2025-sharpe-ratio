{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d6fc17",
   "metadata": {},
   "source": [
    "# FWER control under different processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from functions import generate_autocorrelated_non_gaussian_data\n",
    "from functions import expected_maximum_sharpe_ratio,variance_of_the_maximum_of_k_Sharpe_ratios\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format  = '%(asctime)-15s %(message)s',\n",
    "    datefmt = '%Y-%m-%d %H:%M:%S',\n",
    "    level   = logging.INFO,\n",
    ")\n",
    "def LOG(*args) -> None:\n",
    "    logging.info(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8108186",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = ['gaussian', 'mild', 'moderate', 'severe']\n",
    "RHOs = [0, .2]\n",
    "SR0 = 0\n",
    "SR1_list = [.5]\n",
    "T = 60\n",
    "REPS_H0    = 10_000   # null-calibration repetitions\n",
    "REPS_MIX   = 10_000   # mixed H0/H1 repetitions\n",
    "TRIALS = 10\n",
    "P_H1 = .1\n",
    "ALPHA = .05  # Desired FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    # For debugging\n",
    "    MODELS = ['gaussian']\n",
    "    RHOs = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d04f52-d462-4be8-bc4a-45104d757d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Null calibration (P_H1 = 0, global null)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "LOG(\"Starting null calibration (global H0)\")\n",
    "\n",
    "null_srs = { (rho, name): [] for rho in RHOs for name in MODELS }\n",
    "\n",
    "for rho in RHOs:\n",
    "    for name in MODELS:\n",
    "        LOG(f\"[H0 calibration] rho={rho}, model={name}\")\n",
    "        for i in range(REPS_H0):\n",
    "            # All strategies under H0: SR = SR0\n",
    "            X = generate_autocorrelated_non_gaussian_data(\n",
    "                T, TRIALS, rho=rho, SR0=SR0, name=name\n",
    "            )\n",
    "            SR = X.mean(axis=0) / X.std(axis=0)      # Sharpe for each trial\n",
    "            null_srs[(rho, name)].extend(SR)\n",
    "\n",
    "# Compute variance of SR under H0 and the critical max-SR threshold for each (rho, model)\n",
    "calib = {}\n",
    "\n",
    "z_alpha = scipy.stats.norm.ppf(1 - ALPHA)\n",
    "\n",
    "for (rho, name), srs in null_srs.items():\n",
    "    srs = np.asarray(srs)\n",
    "    var_SR0 = np.var(srs, ddof=1)  # empirical variance under pure H0\n",
    "\n",
    "    E_max_SR0 = expected_maximum_sharpe_ratio(\n",
    "        number_of_trials=TRIALS,\n",
    "        variance=var_SR0,\n",
    "    )\n",
    "    sigma_max = math.sqrt(\n",
    "        variance_of_the_maximum_of_k_Sharpe_ratios(\n",
    "            number_of_trials=TRIALS,\n",
    "            variance=var_SR0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    SR0_adj = SR0 + E_max_SR0\n",
    "    SR_c    = SR0_adj + sigma_max * z_alpha\n",
    "\n",
    "    calib[(rho, name)] = {\n",
    "        \"var_SR0\":   var_SR0,\n",
    "        \"E_max_SR0\": E_max_SR0,\n",
    "        \"sigma_max\": sigma_max,\n",
    "        \"SR0_adj\":   SR0_adj,\n",
    "        \"SR_c\":      SR_c,\n",
    "    }\n",
    "\n",
    "# Optional: inspect calibration\n",
    "calib_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"rho\": rho, \"name\": name, **vals}\n",
    "        for (rho, name), vals in calib.items()\n",
    "    ]\n",
    ")\n",
    "LOG(\"Null calibration completed\")\n",
    "display(calib_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ee167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 minutes\n",
    "\n",
    "# Stage 2: Mixed H0 / H1 experiment, using fixed SR_c from calibration\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "LOG(\"Starting mixed H0/H1 experiment\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for rho in RHOs:\n",
    "    for name in MODELS:\n",
    "        SR_c_info = calib[(rho, name)]\n",
    "        SR_c      = SR_c_info[\"SR_c\"]\n",
    "        E_max_SR0 = SR_c_info[\"E_max_SR0\"]\n",
    "        sigma_max = SR_c_info[\"sigma_max\"]\n",
    "        SR0_adj   = SR_c_info[\"SR0_adj\"]\n",
    "\n",
    "        for SR1 in SR1_list:\n",
    "            LOG(f\"[Mixed] rho={rho}, model={name}, SR1={SR1}\")\n",
    "            for it in range(REPS_MIX):\n",
    "\n",
    "                # Assign H1 / H0 per trial\n",
    "                H1 = np.random.uniform(size=TRIALS) < P_H1\n",
    "                H1.sort()   # cosmetic; does not affect distribution\n",
    "\n",
    "                X0 = X1 = None\n",
    "                K1 = H1.sum()\n",
    "                K0 = TRIALS - K1\n",
    "\n",
    "                if K0 > 0:\n",
    "                    X0 = generate_autocorrelated_non_gaussian_data(\n",
    "                        T, K0, rho=rho, SR0=SR0, name=name\n",
    "                    )\n",
    "                if K1 > 0:\n",
    "                    X1 = generate_autocorrelated_non_gaussian_data(\n",
    "                        T, K1, rho=rho, SR0=SR1, name=name\n",
    "                    )\n",
    "\n",
    "                if X0 is None:\n",
    "                    X = X1\n",
    "                elif X1 is None:\n",
    "                    X = X0\n",
    "                else:\n",
    "                    X = np.concatenate([X0, X1], axis=1)\n",
    "\n",
    "                # Moment diagnostics of the combined panel\n",
    "                gamma3 = scipy.stats.skew(X.flatten())\n",
    "                gamma4 = scipy.stats.kurtosis(X.flatten(), fisher=False)\n",
    "\n",
    "                # Sharpe ratios per trial\n",
    "                SR = X.mean(axis=0) / X.std(axis=0)\n",
    "                sr_max = np.max(SR)\n",
    "                var_SR_emp = np.var(SR, ddof=1)  # empirical within-iteration variance (diagnostic)\n",
    "\n",
    "                # Global decision at iteration level (FWER test)\n",
    "                reject = sr_max > SR_c\n",
    "\n",
    "                # Store per-trial rows, carrying the iteration-level decision\n",
    "                tmp = pd.DataFrame({\n",
    "                    \"SR\":        SR,\n",
    "                    \"H1\":        H1,\n",
    "                })\n",
    "                tmp[\"rho\"]       = rho\n",
    "                tmp[\"name\"]      = name\n",
    "                tmp[\"SR1\"]       = SR1\n",
    "                tmp[\"iteration\"] = it\n",
    "                tmp[\"Max(SR)\"]   = sr_max\n",
    "                tmp[\"Var[SR]\"]   = var_SR_emp\n",
    "                tmp[\"gamma3\"]    = gamma3\n",
    "                tmp[\"gamma4\"]    = gamma4\n",
    "                tmp[\"SR_c\"]      = SR_c\n",
    "                tmp[\"SR0_adj\"]   = SR0_adj         # same for this (rho,name)\n",
    "                tmp[\"E[Max(SR)]\"] = E_max_SR0\n",
    "                tmp[\"sigma_max\"] = sigma_max\n",
    "                tmp[\"Reject\"]    = reject          # same for all trials in this iteration\n",
    "\n",
    "                rows.append(tmp)\n",
    "\n",
    "d = pd.concat(rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation: performance metrics\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "results = []\n",
    "\n",
    "for rho in RHOs:\n",
    "    for name in MODELS:\n",
    "        for SR1 in SR1_list:\n",
    "            tmp = d[\n",
    "                (d[\"rho\"] == rho)\n",
    "                & (d[\"name\"] == name)\n",
    "                & (d[\"SR1\"] == SR1)\n",
    "            ]\n",
    "\n",
    "            # Per-strategy truth\n",
    "            y_true_strat = tmp[\"H1\"].values.astype(bool)\n",
    "\n",
    "            # Per-iteration decision, replicated at strategy level\n",
    "            y_pred_iter  = tmp[\"Reject\"].values.astype(bool)\n",
    "\n",
    "            # FPP: false-positive proportion among H0 strategies\n",
    "            mask_H0 = ~y_true_strat\n",
    "            if mask_H0.sum() > 0:\n",
    "                FPP = np.sum(y_pred_iter & mask_H0) / mask_H0.sum()\n",
    "            else:\n",
    "                FPP = np.nan\n",
    "\n",
    "            # Precision/recall/F1 with per-strategy labeling\n",
    "            if (y_pred_iter.any()) and (y_true_strat.any()):\n",
    "                precision = precision_score(y_true_strat, y_pred_iter)\n",
    "                recall    = recall_score(y_true_strat, y_pred_iter)\n",
    "                f1        = f1_score(y_true_strat, y_pred_iter)\n",
    "            else:\n",
    "                # handle degenerate cases gracefully\n",
    "                precision = np.nan\n",
    "                recall    = np.nan\n",
    "                f1        = np.nan\n",
    "\n",
    "            # Empirical FWER at iteration level: P(reject | all H0)\n",
    "            # To get this, restrict to iterations with no H1 in that iteration:\n",
    "            it_group = tmp.groupby(\"iteration\")\n",
    "            it_df    = it_group[\"H1\"].agg(any_H1=lambda x: x.any())\n",
    "            it_rej   = it_group[\"Reject\"].first()\n",
    "\n",
    "            mask_all_H0_iters = ~it_df[\"any_H1\"].values\n",
    "            if mask_all_H0_iters.sum() > 0:\n",
    "                FWER_emp = np.mean(it_rej.values[mask_all_H0_iters])\n",
    "            else:\n",
    "                FWER_emp = np.nan\n",
    "\n",
    "            results.append({\n",
    "                \"name\":      name,\n",
    "                \"rho\":       rho,\n",
    "                \"SR1\":       SR1,\n",
    "                \"T\":         T,\n",
    "                \"P_H1\":      P_H1,\n",
    "                \"gamma3\":    tmp[\"gamma3\"].mean(),\n",
    "                \"gamma4\":    tmp[\"gamma4\"].mean(),\n",
    "                \"SR_c\":      tmp[\"SR_c\"].mean(),\n",
    "                \"H1_mean\":   tmp[\"H1\"].mean(),\n",
    "                \"precision\": precision,\n",
    "                \"recall\":    recall,\n",
    "                \"f1\":        f1,\n",
    "                \"FPP\":       FPP,\n",
    "                \"FWER_emp\":  FWER_emp,\n",
    "                \"alpha\":     ALPHA,\n",
    "            })\n",
    "\n",
    "results = pd.DataFrame(results).sort_values([\"name\", \"rho\", \"SR1\"]).reset_index(drop=True)\n",
    "results_rounded = results.round(3)\n",
    "\n",
    "# Save if desired\n",
    "results.to_csv(\"exhibit_4_corrected.csv\", index=False)\n",
    "\n",
    "display(results_rounded)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
