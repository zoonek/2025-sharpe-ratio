{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a23d75",
   "metadata": {},
   "source": [
    "# Monte Carlo Experiment: PSR test vs Non-Central Student’s t-distribution test\n",
    "\n",
    "**Goal:** For each target Sharpe SR₀, generate a returns-realistic (neg-skew, leptokurtic) mixture of Gaussians whose population Sharpe equals SR₀, and then evaluate PSR vs t-test against that SR₀.\n",
    "\n",
    "**Data-Generating Process:**\n",
    "- Mixture body: Normal(μ_core, σ_core); tail: Normal(μ_tail, σ_tail) with prob p_tail (negative shocks).\n",
    "- To set SR₀: compute the mixture population σ at zero mean, then add a constant μ_shift = SR₀·σ to all observations. (Adding a constant preserves skewness/kurtosis, and sets E[r]/σ = SR₀.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# --- settings ---\n",
    "REPS = 10_000\n",
    "T = 252*5                       # 5y daily\n",
    "SR0_annual_list = [0.0, 0.5, 1., 1.5, 2.]\n",
    "SR0_list = [s/np.sqrt(252) for s in SR0_annual_list]\n",
    "RSEED = 2025\n",
    "# Mixture configs: (name, p_tail, mu_tail, sigma_tail, sigma_core)\n",
    "configs = [\n",
    "    (\"mild\",     0.04, -0.03, 0.015, 0.010),\n",
    "    (\"moderate\", 0.03, -0.045, 0.020, 0.010),\n",
    "    (\"severe\",   0.02, -0.060, 0.025, 0.010),\n",
    "]\n",
    "\n",
    "def mixture_variance(p_tail, mu_tail, sigma_tail, mu_core, sigma_core):\n",
    "    w = 1.0 - p_tail\n",
    "    mu = w*mu_core + p_tail*mu_tail\n",
    "    m2 = w*(sigma_core**2 + mu_core**2) + p_tail*(sigma_tail**2 + mu_tail**2)\n",
    "    return m2 - mu**2\n",
    "\n",
    "def gen_with_true_SR0(reps, T, cfg, SR0, seed):\n",
    "    name, p, mu_tail, sig_tail, sig_core = cfg\n",
    "    # Zero-mean baseline mixture (choose mu_core so mean=0)\n",
    "    mu_core0 = - p*mu_tail/(1.0 - p)\n",
    "    std0 = np.sqrt(mixture_variance(p, mu_tail, sig_tail, mu_core0, sig_core))\n",
    "    mu_shift = SR0 * std0  # sets population Sharpe to SR0, preserves skew/kurt\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mask = rng.random((reps, T)) < p\n",
    "    X = rng.normal(mu_core0 + mu_shift, sig_core, size=(reps, T))\n",
    "    X[mask] = rng.normal(mu_tail + mu_shift, sig_tail, size=mask.sum())\n",
    "    return X\n",
    "\n",
    "def psr_z_T(X, SR0):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    skew = stats.skew(X, axis=1, bias=False)\n",
    "    kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "    den = np.sqrt((1.0/Tn) * (1.0 - skew*SR0 + ((kappa-1.0)/4.0)*(SR0**2)))\n",
    "    return (sr_hat - SR0)/den\n",
    "\n",
    "def t_stat(X, SR0):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    return np.sqrt(Tn)*(sr_hat - SR0)\n",
    "\n",
    "rows = []\n",
    "for cfg in configs:\n",
    "    for SR0 in SR0_list:\n",
    "        X = gen_with_true_SR0(REPS, T, cfg, SR0, seed=RSEED + int(1e6*SR0) + hash(cfg[0])%10000)\n",
    "        # realized moments\n",
    "        avg_skew = float(np.mean(stats.skew(X, axis=1, bias=False)))\n",
    "        avg_exk  = float(np.mean(stats.kurtosis(X, axis=1, fisher=True, bias=False)))\n",
    "        # stats and KS\n",
    "        z = psr_z_T(X, SR0)\n",
    "        t = t_stat(X, SR0)\n",
    "        # stats and KS (probability space)\n",
    "        psr = stats.norm.cdf(z)\n",
    "        ks_psr = stats.kstest(psr, 'uniform')\n",
    "        p_t = stats.t.sf(t, df=T-1) if SR0 == 0 else stats.nct.sf(t, df=T-1, nc=np.sqrt(T)*SR0)\n",
    "        ks_t   = stats.kstest(p_t, 'uniform')\n",
    "        rows.append({\n",
    "            'config': cfg[0], 'T': T,\n",
    "            'SR0_annual': SR0*np.sqrt(252),\n",
    "            'avg_skew': avg_skew, 'avg_excess_kurtosis': avg_exk,\n",
    "            'KS_PSR_D': float(ks_psr.statistic), 'KS_t_D': float(ks_t.statistic),\n",
    "            'PSR_better?': float(ks_psr.statistic) < float(ks_t.statistic),\n",
    "        })\n",
    "df = pd.DataFrame(rows).round(6)\n",
    "df.to_csv('appendix_1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156ae07-735f-4ffd-a286-8646dcd556dd",
   "metadata": {},
   "source": [
    "# Precision and Recall of PSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0160de-0e76-4320-809b-5a7cb0a4bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SR0 = 0, SR1 ∈ {0.5, 1.0, 1.5, 2.0}\n",
    "\n",
    "SR0_annual = 0.0\n",
    "SR0_daily  = 0.0\n",
    "SR1_annual_list = [0.5, 1.0, 1.5, 2.0]\n",
    "SR1_daily_list  = [s/np.sqrt(252) for s in SR1_annual_list]\n",
    "\n",
    "def _confusion_metrics(y_true, pvals, alpha=0.05):\n",
    "    yhat = (pvals < alpha)\n",
    "    TP = int(((y_true==1)&(yhat)).sum())\n",
    "    FP = int(((y_true==0)&(yhat)).sum())\n",
    "    TN = int(((y_true==0)&(~yhat)).sum())\n",
    "    FN = int(((y_true==1)&(~yhat)).sum())\n",
    "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
    "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
    "    f1   = (2*prec*rec)/(prec+rec) if (prec>0 and rec>0) else (0.0 if (prec==0 or rec==0) else np.nan)\n",
    "    return prec, rec, f1\n",
    "\n",
    "rows = []\n",
    "for cfg in configs:\n",
    "    for SR1_daily, SR1_annual in zip(SR1_daily_list, SR1_annual_list):\n",
    "        # Null: SR = 0 ; Alternative: SR = SR1 (annual)\n",
    "        X0 = gen_with_true_SR0(REPS, T, cfg, SR0=SR0_daily, seed=RSEED)\n",
    "        X1 = gen_with_true_SR0(REPS, T, cfg, SR0=SR1_daily, seed=RSEED+1)\n",
    "        y_true = np.r_[np.zeros(len(X0), dtype=int), np.ones(len(X1), dtype=int)]\n",
    "\n",
    "        # PSR one-sided test (H1: SR > 0)\n",
    "        p_psr = np.r_[stats.norm.sf(psr_z_T(X0, SR0_daily)),\n",
    "                      stats.norm.sf(psr_z_T(X1, SR0_daily))]\n",
    "        prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "\n",
    "        rows.append({\n",
    "            \"config\": cfg[0],\n",
    "            \"SR1_annual\": SR1_annual,\n",
    "            \"PSR_precision\": prec,\n",
    "            \"PSR_recall\": rec,\n",
    "            \"PSR_F1\": f1\n",
    "        })\n",
    "\n",
    "psr_table = pd.DataFrame(rows).sort_values(\n",
    "    [\"config\",\"SR1_annual\"]\n",
    ").set_index([\"config\",\"SR1_annual\"]).round(4)\n",
    "psr_table.to_csv('appendix_2.csv')\n",
    "psr_table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025-sharpe-ratio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
