{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a23d75",
   "metadata": {},
   "source": [
    "# Monte Carlo Experiment: PSR test vs Non-Central Student’s t-distribution test\n",
    "\n",
    "**Goal:** For each target Sharpe SR₀, generate a returns-realistic (neg-skew, leptokurtic) mixture of Gaussians whose population Sharpe equals SR₀, and then evaluate PSR vs t-test against that SR₀.\n",
    "\n",
    "**Data-Generating Process:**\n",
    "- Mixture body: Normal(μ_core, σ_core); tail: Normal(μ_tail, σ_tail) with prob p_tail (negative shocks).\n",
    "- To set SR₀: compute the mixture population σ at zero mean, then add a constant μ_shift = SR₀·σ to all observations. (Adding a constant preserves skewness/kurtosis, and sets E[r]/σ = SR₀.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# --- settings ---\n",
    "REPS = 10_000\n",
    "T = 252*5                       # 5y daily\n",
    "SR0_annual_list = [0.0, 0.5, 1., 1.5, 2.]\n",
    "SR0_list = [s/np.sqrt(252) for s in SR0_annual_list]\n",
    "RSEED = 2025\n",
    "# Mixture configs: (name, p_tail, mu_tail, sigma_tail, sigma_core)\n",
    "configs = [\n",
    "    (\"gaussian\", 0.00, 0.00, 0.010, 0.010),\n",
    "    (\"mild\",     0.04, -0.03, 0.015, 0.010),\n",
    "    (\"moderate\", 0.03, -0.045, 0.020, 0.010),\n",
    "    (\"severe\",   0.02, -0.060, 0.025, 0.010),\n",
    "]\n",
    "\n",
    "def mixture_variance(p_tail, mu_tail, sigma_tail, mu_core, sigma_core):\n",
    "    w = 1.0 - p_tail\n",
    "    mu = w*mu_core + p_tail*mu_tail\n",
    "    m2 = w*(sigma_core**2 + mu_core**2) + p_tail*(sigma_tail**2 + mu_tail**2)\n",
    "    return m2 - mu**2\n",
    "\n",
    "def gen_with_true_SR0(reps, T, cfg, SR0, seed):\n",
    "    name, p, mu_tail, sig_tail, sig_core = cfg\n",
    "    # Zero-mean baseline mixture (choose mu_core so mean=0)\n",
    "    mu_core0 = - p*mu_tail/(1.0 - p)\n",
    "    std0 = np.sqrt(mixture_variance(p, mu_tail, sig_tail, mu_core0, sig_core))\n",
    "    mu_shift = SR0 * std0  # sets population Sharpe to SR0, preserves skew/kurt\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mask = rng.random((reps, T)) < p\n",
    "    X = rng.normal(mu_core0 + mu_shift, sig_core, size=(reps, T))\n",
    "    X[mask] = rng.normal(mu_tail + mu_shift, sig_tail, size=mask.sum())\n",
    "    return X\n",
    "\n",
    "def psr_z_T(X, SR0):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    skew = stats.skew(X, axis=1, bias=False)\n",
    "    kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "    den = np.sqrt((1.0/Tn) * (1.0 - skew*SR0 + ((kappa-1.0)/4.0)*(SR0**2)))\n",
    "    return (sr_hat - SR0)/den\n",
    "\n",
    "def t_stat(X, SR0):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    # return np.sqrt(Tn)*(sr_hat - SR0)   ################### BUG: MISSING VARIANCE (it was added below)\n",
    "    skew = 0\n",
    "    kappa = 3.0\n",
    "    den = np.sqrt((1.0/Tn) * (1.0 - skew*SR0 + ((kappa-1.0)/4.0)*(SR0**2)))\n",
    "    return (sr_hat - SR0)/den    \n",
    "\n",
    "rows = []\n",
    "for cfg in configs:\n",
    "    for SR0 in SR0_list:\n",
    "        X = gen_with_true_SR0(REPS, T, cfg, SR0, seed=RSEED + int(1e6*SR0) + hash(cfg[0])%10000)\n",
    "        # realized moments\n",
    "        avg_skew = float(np.mean(stats.skew(X, axis=1, bias=False)))\n",
    "        avg_exk  = float(np.mean(stats.kurtosis(X, axis=1, fisher=True, bias=False)))\n",
    "        # stats and KS\n",
    "        z = psr_z_T(X, SR0)\n",
    "        t = t_stat(X, SR0)\n",
    "        # stats and KS (probability space)\n",
    "        psr = stats.norm.cdf(z)\n",
    "        ks_psr = stats.kstest(psr, 'uniform')\n",
    "        p_t = stats.t.sf(t, df=T-1) # if SR0 == 0 else stats.nct.sf(t, df=T-1, nc=np.sqrt(T)*SR0)\n",
    "        ks_t   = stats.kstest(p_t, 'uniform')\n",
    "        rows.append({\n",
    "            'config': cfg[0], 'T': T,\n",
    "            'SR0_annual': SR0*np.sqrt(252),\n",
    "            'avg_skew': avg_skew, 'avg_excess_kurtosis': avg_exk,\n",
    "            'KS_PSR_D': float(ks_psr.statistic), 'KS_t_D': float(ks_t.statistic),\n",
    "            'KS_PSR_p': float(ks_psr.pvalue), 'KS_t_p': float(ks_t.pvalue),\n",
    "            'PSR_better?': float(ks_psr.statistic) < float(ks_t.statistic),\n",
    "        })\n",
    "df = pd.DataFrame(rows).round(6)\n",
    "df.to_csv('appendix_1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import sharpe_ratio_variance\n",
    "def my_psr_z_T(X, SR0, rho):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    skew = stats.skew(X, axis=1, bias=False)\n",
    "    kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "    v = sharpe_ratio_variance( SR0, Tn, gamma3=skew, gamma4=kappa, rho=rho, K=1 )\n",
    "    den = np.sqrt(v)\n",
    "    return (sr_hat - SR0)/den\n",
    "\n",
    "if False: \n",
    "    print( psr_z_T(X, SR0) )\n",
    "    print( my_psr_z_T(X, SR0, 0) )  # Same values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from itertools import product\n",
    "from functions import generate_non_gaussian_data, generate_autocorrelated_non_gaussian_data\n",
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f1(name, rho, SR0):\n",
    "    if rho == 0: \n",
    "        X = generate_non_gaussian_data( T, REPS, SR0 = SR0, name = name )\n",
    "    else: \n",
    "        X = generate_autocorrelated_non_gaussian_data( T, REPS, SR0 = SR0, name = name, rho = rho )\n",
    "\n",
    "    X = X.T\n",
    "    avg_skew = float(np.mean(stats.skew(X, axis=1, bias=False)))\n",
    "    avg_exk  = float(np.mean(stats.kurtosis(X, axis=1, fisher=True, bias=False)))\n",
    "    # stats and KS\n",
    "    z = my_psr_z_T(X, SR0, rho)\n",
    "    t = t_stat(X, SR0)\n",
    "    # stats and KS (probability space)\n",
    "    psr = stats.norm.cdf(z)\n",
    "    ks_psr = stats.kstest(psr, 'uniform')\n",
    "    p_t = stats.t.sf(t, df=T-1) # if SR0 == 0 else stats.nct.sf(t, df=T-1, nc=np.sqrt(T)*SR0)\n",
    "    assert len(p_t) == REPS\n",
    "    ks_t   = stats.kstest(p_t, 'uniform')\n",
    "    return {\n",
    "        'name': name,\n",
    "        'rho': rho,\n",
    "        'SR0_annual': SR0*np.sqrt(252),\n",
    "        'avg_skew': avg_skew, 'avg_excess_kurtosis': avg_exk,\n",
    "        'KS_PSR_D': float(ks_psr.statistic), 'KS_t_D': float(ks_t.statistic),\n",
    "        'KS_PSR_p': float(ks_psr.pvalue), 'KS_t_p': float(ks_t.pvalue),\n",
    "        'PSR_better?': float(ks_psr.statistic) < float(ks_t.statistic),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "RHOs = [0, .2]\n",
    "rows = [ \n",
    "    f1.remote(name, rho, SR0) \n",
    "    for name, rho, SR0 in product( ['gaussian', 'mild', 'moderate', 'severe'], RHOs, SR0_list )\n",
    "]\n",
    "rows = [ ray.get(r) for r in tqdm(rows) ]\n",
    "rows = pd.DataFrame( rows )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = rows.copy()\n",
    "d['avg_skew'] = d['avg_skew'].round(1)\n",
    "d['avg_excess_kurtosis'] = d['avg_excess_kurtosis'].round(1)\n",
    "d['Diff'] = d['KS_t_D'] - d['KS_PSR_D']\n",
    "d['KS_PSR_D'] = d['KS_PSR_D'].round(3)\n",
    "d['KS_t_D'] = d['KS_t_D'].round(3)\n",
    "d['KS_PSR_p'] = d['KS_PSR_p'].round(3)\n",
    "d['KS_t_p'] = d['KS_t_p'].round(3)\n",
    "d['Diff'] = d['Diff'].round(3)\n",
    "d.columns = ['Distribution', 'ρ', 'Annual SR0', 'Avg Skew', 'Avg Ex. Kurt', 'KS_PSR', 'KS_t', 'p(KS_PSR)', 'p(KS_t)', 'PSR better?', 'Diff']\n",
    "d.drop(columns=['PSR better?'], inplace=True)\n",
    "d.to_csv('exhibit_1bis.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def highlight_pos_neg(val):\n",
    "    \"\"\"\n",
    "    Highlight negative values in light red, positive in light green.\n",
    "    \"\"\"\n",
    "    color = ''\n",
    "    try:\n",
    "        v = float(val)\n",
    "        if v < 0:\n",
    "            color = 'background-color: #ffd6d6'   # light red\n",
    "        elif v > 0:\n",
    "            color = 'background-color: #d6ffd6'   # light green\n",
    "    except:\n",
    "        color = ''\n",
    "    return color\n",
    "\n",
    "d_fmt = d.copy()\n",
    "for col in d_fmt.columns[1:5]:\n",
    "    d_fmt[col] = d_fmt[col].astype(float).map(lambda x: f'{x:.1f}')\n",
    "for col in d_fmt.columns[5:]:\n",
    "    d_fmt[col] = d_fmt[col].astype(float).map(lambda x: f'{x:.3f}')\n",
    "styled = d_fmt.style.map(highlight_pos_neg, subset=[d.columns[-1]])\n",
    "\n",
    "def add_hr(styler, rows=[4,9,14,19,24,29,34]):\n",
    "    # Create empty DataFrame of same shape to hold style strings\n",
    "    styles = pd.DataFrame(\"\", index=styler.index, columns=styler.columns)\n",
    "    # Apply a thick border to all columns in the specified row\n",
    "    for row in rows:\n",
    "        if row in styles.index:\n",
    "            styles.loc[row, :] = \"border-bottom: 2px solid black;\"\n",
    "    return styles\n",
    "\n",
    "styled = styled.apply(add_hr, axis=None)\n",
    "\n",
    "display(styled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156ae07-735f-4ffd-a286-8646dcd556dd",
   "metadata": {},
   "source": [
    "# Precision and Recall of PSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0160de-0e76-4320-809b-5a7cb0a4bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SR0 = 0, SR1 ∈ {0.5, 1.0, 1.5, 2.0}\n",
    "\n",
    "SR0_annual = 0.0\n",
    "SR0_daily  = 0.0\n",
    "SR1_annual_list = [0.5, 1.0, 1.5, 2.0]\n",
    "SR1_daily_list  = [s/np.sqrt(252) for s in SR1_annual_list]\n",
    "\n",
    "def _confusion_metrics(y_true, pvals, alpha=0.05):\n",
    "    yhat = (pvals < alpha)\n",
    "    TP = int(((y_true==1)&(yhat)).sum())\n",
    "    FP = int(((y_true==0)&(yhat)).sum())\n",
    "    TN = int(((y_true==0)&(~yhat)).sum())\n",
    "    FN = int(((y_true==1)&(~yhat)).sum())\n",
    "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
    "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
    "    f1   = (2*prec*rec)/(prec+rec) if (prec>0 and rec>0) else (0.0 if (prec==0 or rec==0) else np.nan)\n",
    "    return prec, rec, f1\n",
    "\n",
    "rows = []\n",
    "for cfg in configs:\n",
    "    for SR1_daily, SR1_annual in zip(SR1_daily_list, SR1_annual_list):\n",
    "        # Null: SR = 0 ; Alternative: SR = SR1 (annual)\n",
    "        X0 = gen_with_true_SR0(REPS, T, cfg, SR0=SR0_daily, seed=RSEED)\n",
    "        X1 = gen_with_true_SR0(REPS, T, cfg, SR0=SR1_daily, seed=RSEED+1)\n",
    "        y_true = np.r_[np.zeros(len(X0), dtype=int), np.ones(len(X1), dtype=int)]\n",
    "\n",
    "        # PSR one-sided test (H1: SR > 0)\n",
    "        p_psr = np.r_[stats.norm.sf(psr_z_T(X0, SR0_daily)),\n",
    "                      stats.norm.sf(psr_z_T(X1, SR0_daily))]\n",
    "        prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "\n",
    "        rows.append({\n",
    "            \"config\": cfg[0],\n",
    "            \"SR1_annual\": SR1_annual,\n",
    "            \"PSR_precision\": prec,\n",
    "            \"PSR_recall\": rec,\n",
    "            \"PSR_F1\": f1\n",
    "        })\n",
    "\n",
    "psr_table = pd.DataFrame(rows).sort_values(\n",
    "    [\"config\",\"SR1_annual\"]\n",
    ").set_index([\"config\",\"SR1_annual\"]).round(4)\n",
    "psr_table.to_csv('appendix_2.csv')\n",
    "psr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f2(rho, name, SR0_daily, SR1_daily, SR1_annual):\n",
    "    # Null: SR = 0 ; Alternative: SR = SR1 (annual)\n",
    "    if rho == 0:\n",
    "        X0 = generate_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name )\n",
    "        X1 = generate_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name )\n",
    "    else:\n",
    "        X0 = generate_autocorrelated_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name, rho = rho )\n",
    "        X1 = generate_autocorrelated_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name, rho = rho )\n",
    "            \n",
    "    y_true = np.r_[np.zeros(REPS, dtype=int), np.ones(REPS, dtype=int)]\n",
    "\n",
    "    # PSR one-sided test (H1: SR > 0)\n",
    "    p_psr = np.r_[\n",
    "        stats.norm.sf(my_psr_z_T(X0.T, SR0_daily, rho)),\n",
    "        stats.norm.sf(my_psr_z_T(X1.T, SR0_daily, rho)),\n",
    "    ]\n",
    "    prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"rho\": rho, \n",
    "        \"SR1_annual\": SR1_annual,\n",
    "        \"PSR_precision\": prec,\n",
    "        \"PSR_recall\": rec,\n",
    "        \"PSR_F1\": f1\n",
    "    }\n",
    "\n",
    "rows = [\n",
    "    f2.remote(rho, name, SR0_daily, SR1_daily, SR1_annual)\n",
    "    for rho in RHOs\n",
    "    for name in ['gaussian', 'mild', 'moderate', 'severe']\n",
    "    for SR1_daily, SR1_annual in zip(SR1_daily_list, SR1_annual_list)\n",
    "]\n",
    "rows = [ ray.get(r) for r in tqdm(rows) ]\n",
    "rows = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0\n",
    "name = \"gaussian\"\n",
    "SR0_daily = 0\n",
    "SR1_daily = SR1_daily_list[1]\n",
    "SR1_annual = SR1_annual_list[1]\n",
    "\n",
    "X0 = generate_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name )\n",
    "X1 = generate_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name )\n",
    "    \n",
    "y_true = np.r_[np.zeros(REPS, dtype=int), np.ones(REPS, dtype=int)]\n",
    "\n",
    "p_psr = np.r_[\n",
    "    stats.norm.sf(my_psr_z_T(X0.T, SR0_daily, rho)),\n",
    "    stats.norm.sf(my_psr_z_T(X1.T, SR0_daily, rho)),\n",
    "]\n",
    "prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psr_table = pd.DataFrame(rows).sort_values(\n",
    "    [\"name\",\"rho\",\"SR1_annual\"]\n",
    ").set_index([\"name\",\"rho\",\"SR1_annual\"]).round(3)\n",
    "psr_table.to_csv('exhibit_2bis.csv')\n",
    "psr_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
