{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a23d75",
   "metadata": {},
   "source": [
    "# Monte Carlo Experiment: PSR test vs Non-Central Student’s t-distribution test\n",
    "\n",
    "**Goal:** For each target Sharpe SR₀, generate a returns-realistic (neg-skew, leptokurtic) mixture of Gaussians whose population Sharpe equals SR₀, and then evaluate PSR vs t-test against that SR₀.\n",
    "\n",
    "**Data-Generating Process:**\n",
    "- Mixture body: Normal(μ_core, σ_core); tail: Normal(μ_tail, σ_tail) with prob p_tail (negative shocks).\n",
    "- To set SR₀: compute the mixture population σ at zero mean, then add a constant μ_shift = SR₀·σ to all observations. (Adding a constant preserves skewness/kurtosis, and sets E[r]/σ = SR₀.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# --- settings ---\n",
    "REPS = 10_000\n",
    "T = 252*5                       # 5y daily\n",
    "SR0_annual_list = [0.0, 0.5, 1., 1.5, 2.]\n",
    "SR0_list = [s/np.sqrt(252) for s in SR0_annual_list]\n",
    "RSEED = 2025\n",
    "# Mixture configs: (name, p_tail, mu_tail, sigma_tail, sigma_core)\n",
    "configs = [\n",
    "    (\"gaussian\", 0.00, 0.00, 0.010, 0.010),\n",
    "    (\"mild\",     0.04, -0.03, 0.015, 0.010),\n",
    "    (\"moderate\", 0.03, -0.045, 0.020, 0.010),\n",
    "    (\"severe\",   0.02, -0.060, 0.025, 0.010),\n",
    "]\n",
    "\n",
    "def mixture_variance(p_tail, mu_tail, sigma_tail, mu_core, sigma_core):\n",
    "    w = 1.0 - p_tail\n",
    "    mu = w*mu_core + p_tail*mu_tail\n",
    "    m2 = w*(sigma_core**2 + mu_core**2) + p_tail*(sigma_tail**2 + mu_tail**2)\n",
    "    return m2 - mu**2\n",
    "\n",
    "def gen_with_true_SR0(reps, T, cfg, SR0, seed):\n",
    "    name, p, mu_tail, sig_tail, sig_core = cfg\n",
    "    # Zero-mean baseline mixture (choose mu_core so mean=0)\n",
    "    mu_core0 = - p*mu_tail/(1.0 - p)\n",
    "    std0 = np.sqrt(mixture_variance(p, mu_tail, sig_tail, mu_core0, sig_core))\n",
    "    mu_shift = SR0 * std0  # sets population Sharpe to SR0, preserves skew/kurt\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mask = rng.random((reps, T)) < p\n",
    "    X = rng.normal(mu_core0 + mu_shift, sig_core, size=(reps, T))\n",
    "    X[mask] = rng.normal(mu_tail + mu_shift, sig_tail, size=mask.sum())\n",
    "    return X\n",
    "\n",
    "def psr_z_T(X, SR0):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    skew = stats.skew(X, axis=1, bias=False)\n",
    "    kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "    den = np.sqrt((1.0/Tn) * (1.0 - skew*SR0 + ((kappa-1.0)/4.0)*(SR0**2)))\n",
    "    return (sr_hat - SR0)/den\n",
    "\n",
    "def t_stat(X, SR0):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    # return np.sqrt(Tn)*(sr_hat - SR0)   ################### BUG: MISSING VARIANCE (it was added below)\n",
    "    skew = 0\n",
    "    kappa = 3.0\n",
    "    den = np.sqrt((1.0/Tn) * (1.0 - skew*SR0 + ((kappa-1.0)/4.0)*(SR0**2)))\n",
    "    return (sr_hat - SR0)/den    \n",
    "\n",
    "rows = []\n",
    "for cfg in configs:\n",
    "    for SR0 in SR0_list:\n",
    "        X = gen_with_true_SR0(REPS, T, cfg, SR0, seed=RSEED + int(1e6*SR0) + hash(cfg[0])%10000)\n",
    "        # realized moments\n",
    "        avg_skew = float(np.mean(stats.skew(X, axis=1, bias=False)))\n",
    "        avg_exk  = float(np.mean(stats.kurtosis(X, axis=1, fisher=True, bias=False)))\n",
    "        # stats and KS\n",
    "        z = psr_z_T(X, SR0)\n",
    "        t = t_stat(X, SR0)\n",
    "        # stats and KS (probability space)\n",
    "        psr = stats.norm.cdf(z)\n",
    "        ks_psr = stats.kstest(psr, 'uniform')\n",
    "        p_t = stats.t.sf(t, df=T-1) # if SR0 == 0 else stats.nct.sf(t, df=T-1, nc=np.sqrt(T)*SR0)\n",
    "        ks_t   = stats.kstest(p_t, 'uniform')\n",
    "        rows.append({\n",
    "            'config': cfg[0], 'T': T,\n",
    "            'SR0_annual': SR0*np.sqrt(252),\n",
    "            'avg_skew': avg_skew, 'avg_excess_kurtosis': avg_exk,\n",
    "            'KS_PSR_D': float(ks_psr.statistic), 'KS_t_D': float(ks_t.statistic),\n",
    "            'KS_PSR_p': float(ks_psr.pvalue), 'KS_t_p': float(ks_t.pvalue),\n",
    "            'PSR_better?': float(ks_psr.statistic) < float(ks_t.statistic),\n",
    "        })\n",
    "df = pd.DataFrame(rows).round(6)\n",
    "df.to_csv('appendix_1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import sharpe_ratio_variance\n",
    "def my_psr_z_T(X, SR0, rho):\n",
    "    Tn = X.shape[1]\n",
    "    s = X.std(axis=1, ddof=1)\n",
    "    sr_hat = X.mean(axis=1)/s\n",
    "    skew = stats.skew(X, axis=1, bias=False)\n",
    "    kappa = stats.kurtosis(X, axis=1, fisher=True, bias=False) + 3.0\n",
    "    v = sharpe_ratio_variance( SR0, Tn, gamma3=skew, gamma4=kappa, rho=rho, K=1 )\n",
    "    den = np.sqrt(v)\n",
    "    return (sr_hat - SR0)/den\n",
    "\n",
    "if False: \n",
    "    print( psr_z_T(X, SR0) )\n",
    "    print( my_psr_z_T(X, SR0, 0) )  # Same values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from itertools import product\n",
    "from functions import generate_non_gaussian_data, generate_autocorrelated_non_gaussian_data\n",
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f1(name, rho, SR0):\n",
    "    if rho == 0: \n",
    "        X = generate_non_gaussian_data( T, REPS, SR0 = SR0, name = name )\n",
    "    else: \n",
    "        X = generate_autocorrelated_non_gaussian_data( T, REPS, SR0 = SR0, name = name, rho = rho )\n",
    "\n",
    "    X = X.T\n",
    "    avg_skew = float(np.mean(stats.skew(X, axis=1, bias=False)))\n",
    "    avg_exk  = float(np.mean(stats.kurtosis(X, axis=1, fisher=True, bias=False)))\n",
    "    # stats and KS\n",
    "    z = my_psr_z_T(X, SR0, rho)\n",
    "    t = t_stat(X, SR0)\n",
    "    # stats and KS (probability space)\n",
    "    psr = stats.norm.cdf(z)\n",
    "    ks_psr = stats.kstest(psr, 'uniform')\n",
    "    p_t = stats.t.sf(t, df=T-1) # if SR0 == 0 else stats.nct.sf(t, df=T-1, nc=np.sqrt(T)*SR0)\n",
    "    assert len(p_t) == REPS\n",
    "    ks_t   = stats.kstest(p_t, 'uniform')\n",
    "    return {\n",
    "        'name': name,\n",
    "        'rho': rho,\n",
    "        'SR0_annual': SR0*np.sqrt(252),\n",
    "        'avg_skew': avg_skew, 'avg_excess_kurtosis': avg_exk,\n",
    "        'KS_PSR_D': float(ks_psr.statistic), 'KS_t_D': float(ks_t.statistic),\n",
    "        'KS_PSR_p': float(ks_psr.pvalue), 'KS_t_p': float(ks_t.pvalue),\n",
    "        'PSR_better?': float(ks_psr.statistic) < float(ks_t.statistic),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "RHOs = [0, .2]\n",
    "rows = [ \n",
    "    f1.remote(name, rho, SR0) \n",
    "    for name, rho, SR0 in product( ['gaussian', 'mild', 'moderate', 'severe'], RHOs, SR0_list )\n",
    "]\n",
    "rows = [ ray.get(r) for r in tqdm(rows) ]\n",
    "rows = pd.DataFrame( rows )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = rows.copy()\n",
    "d['avg_skew'] = d['avg_skew'].round(1)\n",
    "d['avg_excess_kurtosis'] = d['avg_excess_kurtosis'].round(1)\n",
    "d['Diff'] = d['KS_t_D'] - d['KS_PSR_D']\n",
    "d['KS_PSR_D'] = d['KS_PSR_D'].round(3)\n",
    "d['KS_t_D'] = d['KS_t_D'].round(3)\n",
    "d['KS_PSR_p'] = d['KS_PSR_p'].round(3)\n",
    "d['KS_t_p'] = d['KS_t_p'].round(3)\n",
    "d['Diff'] = d['Diff'].round(3)\n",
    "d.columns = ['Distribution', 'ρ', 'Annual SR0', 'Avg Skew', 'Avg Ex. Kurt', 'KS_PSR', 'KS_t', 'p(KS_PSR)', 'p(KS_t)', 'PSR better?', 'Diff']\n",
    "d.drop(columns=['PSR better?'], inplace=True)\n",
    "d.to_csv('exhibit_1bis.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def highlight_pos_neg(val):\n",
    "    \"\"\"\n",
    "    Highlight negative values in light red, positive in light green.\n",
    "    \"\"\"\n",
    "    color = ''\n",
    "    try:\n",
    "        v = float(val)\n",
    "        if v < 0:\n",
    "            color = 'background-color: #ffd6d6'   # light red\n",
    "        elif v > 0:\n",
    "            color = 'background-color: #d6ffd6'   # light green\n",
    "    except:\n",
    "        color = ''\n",
    "    return color\n",
    "\n",
    "d_fmt = d.copy()\n",
    "for col in d_fmt.columns[1:5]:\n",
    "    d_fmt[col] = d_fmt[col].astype(float).map(lambda x: f'{x:.1f}')\n",
    "for col in d_fmt.columns[5:]:\n",
    "    d_fmt[col] = d_fmt[col].astype(float).map(lambda x: f'{x:.3f}')\n",
    "styled = d_fmt.style.map(highlight_pos_neg, subset=[d.columns[-1]])\n",
    "\n",
    "def add_hr(styler, rows=[4,9,14,19,24,29,34]):\n",
    "    # Create empty DataFrame of same shape to hold style strings\n",
    "    styles = pd.DataFrame(\"\", index=styler.index, columns=styler.columns)\n",
    "    # Apply a thick border to all columns in the specified row\n",
    "    for row in rows:\n",
    "        if row in styles.index:\n",
    "            styles.loc[row, :] = \"border-bottom: 2px solid black;\"\n",
    "    return styles\n",
    "\n",
    "styled = styled.apply(add_hr, axis=None)\n",
    "\n",
    "display(styled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156ae07-735f-4ffd-a286-8646dcd556dd",
   "metadata": {},
   "source": [
    "# Precision and Recall of PSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0160de-0e76-4320-809b-5a7cb0a4bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SR0 = 0, SR1 ∈ {0.5, 1.0, 1.5, 2.0}\n",
    "\n",
    "SR0_annual = 0.0\n",
    "SR0_daily  = 0.0\n",
    "SR1_annual_list = [0.5, 1.0, 1.5, 2.0]\n",
    "SR1_daily_list  = [s/np.sqrt(252) for s in SR1_annual_list]\n",
    "\n",
    "SR1_daily_list = [ .15, .30, .45, .60 ]\n",
    "T = 12 * 5\n",
    "\n",
    "def _confusion_metrics(y_true, pvals, alpha=0.05):\n",
    "    yhat = (pvals < alpha)\n",
    "    TP = int(((y_true==1)&(yhat)).sum())\n",
    "    FP = int(((y_true==0)&(yhat)).sum())\n",
    "    TN = int(((y_true==0)&(~yhat)).sum())\n",
    "    FN = int(((y_true==1)&(~yhat)).sum())\n",
    "    prec = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
    "    rec  = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
    "    f1   = (2*prec*rec)/(prec+rec) if (prec>0 and rec>0) else (0.0 if (prec==0 or rec==0) else np.nan)\n",
    "    return prec, rec, f1\n",
    "\n",
    "rows = []\n",
    "for cfg in configs:\n",
    "    for SR1_daily, SR1_annual in zip(SR1_daily_list, SR1_annual_list):\n",
    "        # Null: SR = 0 ; Alternative: SR = SR1 (annual)\n",
    "        X0 = gen_with_true_SR0(REPS, T, cfg, SR0=SR0_daily, seed=RSEED)\n",
    "        X1 = gen_with_true_SR0(REPS, T, cfg, SR0=SR1_daily, seed=RSEED+1)\n",
    "        y_true = np.r_[np.zeros(len(X0), dtype=int), np.ones(len(X1), dtype=int)]\n",
    "\n",
    "        # PSR one-sided test (H1: SR > 0)\n",
    "        p_psr = np.r_[stats.norm.sf(psr_z_T(X0, SR0_daily)),\n",
    "                      stats.norm.sf(psr_z_T(X1, SR0_daily))]\n",
    "        prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "\n",
    "        rows.append({\n",
    "            \"config\": cfg[0],\n",
    "            \"SR1\": SR1_daily,\n",
    "            #\"SR1_annual\": SR1_annual,\n",
    "            \"PSR_precision\": prec,\n",
    "            \"PSR_recall\": rec,\n",
    "            \"PSR_F1\": f1\n",
    "        })\n",
    "\n",
    "psr_table = pd.DataFrame(rows).sort_values(\n",
    "    [\"config\",\"SR1\"]\n",
    ").set_index([\"config\",\"SR1\"]).round(4)\n",
    "psr_table.to_csv('appendix_2.csv')\n",
    "psr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f2(rho, name, SR0_daily, SR1_daily):\n",
    "    # Null: SR = 0 ; Alternative: SR = SR1 (annual)\n",
    "    if rho == 0:\n",
    "        X0 = generate_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name )\n",
    "        X1 = generate_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name )\n",
    "    else:\n",
    "        X0 = generate_autocorrelated_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name, rho = rho )\n",
    "        X1 = generate_autocorrelated_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name, rho = rho )\n",
    "            \n",
    "    y_true = np.r_[np.zeros(REPS, dtype=int), np.ones(REPS, dtype=int)]\n",
    "\n",
    "    # PSR one-sided test (H1: SR > 0)\n",
    "    p_psr = np.r_[\n",
    "        stats.norm.sf(my_psr_z_T(X0.T, SR0_daily, rho)),\n",
    "        stats.norm.sf(my_psr_z_T(X1.T, SR0_daily, rho)),\n",
    "    ]\n",
    "    prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"rho\": rho, \n",
    "        \"SR1\": SR1_daily,\n",
    "        \"PSR_precision\": prec,\n",
    "        \"PSR_recall\": rec,\n",
    "        \"PSR_F1\": f1\n",
    "    }\n",
    "\n",
    "rows = [\n",
    "    f2.remote(rho, name, SR0_daily, SR1_daily)\n",
    "    for rho in RHOs\n",
    "    for name in ['gaussian', 'mild', 'moderate', 'severe']\n",
    "    for SR1_daily in SR1_daily_list\n",
    "]\n",
    "rows = [ ray.get(r) for r in tqdm(rows) ]\n",
    "rows = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "        \n",
    "    rho = 0\n",
    "    name = \"gaussian\"\n",
    "    SR0_daily = 0\n",
    "    SR1_daily = SR1_daily_list[1]\n",
    "    SR1_annual = SR1_annual_list[1]\n",
    "\n",
    "    X0 = generate_non_gaussian_data( T, REPS, SR0 = SR0_daily, name = name )\n",
    "    X1 = generate_non_gaussian_data( T, REPS, SR0 = SR1_daily, name = name )\n",
    "        \n",
    "    y_true = np.r_[np.zeros(REPS, dtype=int), np.ones(REPS, dtype=int)]\n",
    "\n",
    "    p_psr = np.r_[\n",
    "        stats.norm.sf(my_psr_z_T(X0.T, SR0_daily, rho)),\n",
    "        stats.norm.sf(my_psr_z_T(X1.T, SR0_daily, rho)),\n",
    "    ]\n",
    "    prec, rec, f1 = _confusion_metrics(y_true, p_psr, alpha=0.05)\n",
    "    rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psr_table = pd.DataFrame(rows).sort_values(\n",
    "    [\"name\",\"rho\",\"SR1\"]\n",
    ").set_index([\"name\",\"rho\",\"SR1\"]).round(3)\n",
    "psr_table.to_csv('exhibit_2bis.csv')\n",
    "psr_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ccd198",
   "metadata": {},
   "source": [
    "# Plot the variance as a function of the autocorrelation\n",
    "Compare different estimators of the variance (Gaussian, Gaussian + autocorrelation, Non-Gaussian iid, Non-Gaussian + autocorrelation) with a simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "def legend_thick(ax, *args, **kwargs):\n",
    "    leg = ax.legend(*args, **kwargs)\n",
    "    for i in leg.legend_handles:\n",
    "        i.set_linewidth(7)\n",
    "        i.set_solid_capstyle('butt')\n",
    "\n",
    "def remove_empty_axes(axs: np.ndarray) -> None:\n",
    "    for ax in axs.flatten():\n",
    "        if (not ax.lines) and (not ax.collections) and (not ax.has_data()):\n",
    "            ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu     = .036\n",
    "sigma  = .079\n",
    "T      = 24\n",
    "gamma3 = -2.448\n",
    "gamma4 = 10.164\n",
    "rhos = np.linspace(0, .5, 100)          \n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize=(12,8), layout='constrained')\n",
    "for SR, ax in zip(SR0_annual_list, axs.flatten()):\n",
    "    SR = SR/np.sqrt(12)\n",
    "    variances1 = [ sharpe_ratio_variance( SR, T, K=1 ) for rho in rhos ]\n",
    "    variances2 = [ sharpe_ratio_variance( SR, T, gamma3=gamma3, gamma4=gamma4, K=1 ) for rho in rhos ]\n",
    "    variances3 = [ sharpe_ratio_variance( SR, T, rho=rho, K=1 ) for rho in rhos ]\n",
    "    variances4 = [ sharpe_ratio_variance( SR, T, gamma3=gamma3, gamma4=gamma4, rho=rho, K=1 ) for rho in rhos ]\n",
    "    ax.plot(rhos, variances1, label='Gaussian')\n",
    "    ax.plot(rhos, variances3, label='Gaussian + autocorrelation')\n",
    "    ax.plot(rhos, variances2, label='Non-Gaussian iid')\n",
    "    ax.plot(rhos, variances4, label='Non-Gaussian + autocorrelation')\n",
    "    ax.axhline( 0, color='black', linewidth=1 )\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1])\n",
    "    ax.set_xlabel('Autocorrelation')\n",
    "    ax.set_ylabel('Variance')\n",
    "    ax.set_title(f'Variance of the Sharpe Ratio (SR={SR:.2f})')\n",
    "remove_empty_axes(axs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = []\n",
    "for SR in SR0_annual_list:\n",
    "    SR = SR/np.sqrt(12)\n",
    "    for rho in tqdm(rhos):\n",
    "        X = generate_autocorrelated_non_gaussian_data( T, 10_000, SR0 = SR, name = \"severe\", rho = rho )\n",
    "        gamma3 = scipy.stats.skew(X.flatten())                    # Skewness\n",
    "        gamma4 = scipy.stats.kurtosis(X.flatten(), fisher=False)  # Kurtosis (not excess kurtosis)\n",
    "        T = X.shape[0]\n",
    "        variances.append( { \n",
    "            'SR': SR,\n",
    "            'rho': rho,\n",
    "            'simulation': np.var( X.mean(axis=0) / X.std(axis=0) ),\n",
    "            'Gaussian': sharpe_ratio_variance( SR, T ),\n",
    "            'Gaussian + autocorrelation': sharpe_ratio_variance( SR, T, rho=rho ),\n",
    "            'Non-Gaussian iid': sharpe_ratio_variance( SR, T, gamma3=gamma3, gamma4=gamma4 ),\n",
    "            'Non-Gaussian + autocorrelation': sharpe_ratio_variance( SR, T, gamma3=gamma3, gamma4=gamma4, rho=rho ),\n",
    "        } )\n",
    "variances = pd.DataFrame(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6), layout='constrained')\n",
    "for i, SR in enumerate(variances['SR'].unique()):\n",
    "    ax = axs.flatten()[i]\n",
    "    tmp = variances[variances['SR'] == SR]\n",
    "    for column in tmp.columns[2:]:\n",
    "        ax.plot(tmp['rho'], tmp[column], label=column)\n",
    "    ax.axhline( 0, linewidth = 1, color = 'black', linestyle = ':' )\n",
    "    ax.set_ylim( 0, variances.iloc[:,2:].max().max() * 1.05 )\n",
    "    if i == 0: \n",
    "        legend_thick(ax)\n",
    "    ax.set_xlabel('Autocorrelation')\n",
    "    ax.set_ylabel('Variance')\n",
    "    ax.set_title(f'SR={SR:.2f}')\n",
    "remove_empty_axes(axs)\n",
    "fig.suptitle( f\"Variance of the Sharpe ratio (T={T})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03800fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f3(SR, rho, T, name):\n",
    "    X = generate_autocorrelated_non_gaussian_data( T, 10_000, SR0 = SR, name = name, rho = rho )\n",
    "    gamma3 = scipy.stats.skew(X.flatten())                    # Skewness\n",
    "    gamma4 = scipy.stats.kurtosis(X.flatten(), fisher=False)  # Kurtosis (not excess kurtosis)\n",
    "    return {\n",
    "        'name': name,\n",
    "        'SR': SR,\n",
    "        'rho': rho,\n",
    "        'simulation': np.var( X.mean(axis=0) / X.std(axis=0) ),\n",
    "        'Gaussian iid': sharpe_ratio_variance( SR, T ),\n",
    "        'Gaussian + autocorrelation': sharpe_ratio_variance( SR, T, rho=rho ),\n",
    "        'Non-Gaussian iid': sharpe_ratio_variance( SR, T, gamma3=gamma3, gamma4=gamma4 ),\n",
    "        'Non-Gaussian + autocorrelation': sharpe_ratio_variance( SR, T, gamma3=gamma3, gamma4=gamma4, rho=rho ),\n",
    "    }\n",
    "\n",
    "YEARS = 5\n",
    "PERIODS_PER_YEAR = 12  # 252\n",
    "\n",
    "T = YEARS * PERIODS_PER_YEAR\n",
    "SRs = SR0_annual_list/np.sqrt(PERIODS_PER_YEAR)\n",
    "SRs = [ 0, .15, .30, .45, .60 ]\n",
    "rhos = np.linspace(0, .5, 100)\n",
    "variances = [ \n",
    "    f3.remote(SR, rho, T, name) \n",
    "    for SR in SRs\n",
    "    for rho in rhos\n",
    "    for name in ['gaussian', 'mild', 'moderate', 'severe']\n",
    "]\n",
    "variances = [ ray.get(v) for v in tqdm(variances) ]\n",
    "variances = pd.DataFrame(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in variances['name'].unique():\n",
    "        \n",
    "    fig, axs = plt.subplots( 2, 3, figsize=(12, 6), layout='constrained', dpi = 300 )\n",
    "    for i, SR in enumerate(variances['SR'].unique()):\n",
    "        ax = axs.flatten()[i]\n",
    "        i1 = variances['SR'] == SR\n",
    "        i2 = variances['name'] == name\n",
    "        tmp = variances[ i1 & i2 ]\n",
    "        for column in tmp.columns[3:]:\n",
    "            ax.plot(tmp['rho'], tmp[column], label=column)\n",
    "        ax.axhline( 0, linewidth = 1, color = 'black', linestyle = ':' )\n",
    "        ax.set_ylim( 0, variances[i2].iloc[:,3:].max().max() * 1.05 )\n",
    "        if i == 0: \n",
    "            #legend_thick(ax)\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.set_xlabel('Autocorrelation')\n",
    "        ax.set_ylabel('Variance')\n",
    "        ax.set_title(f'SR={SR:.2f}')\n",
    "    remove_empty_axes(axs)\n",
    "    \n",
    "    ax = axs.flatten()[-1]\n",
    "    legend_thick( ax, handles, labels, loc = 'center' )\n",
    "\n",
    "    fig.suptitle( f\"Variance of the Sharpe ratio (distribution={name}, T={T})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "\n",
    "if False: \n",
    "        \n",
    "    for name in variances['name'].unique():\n",
    "            \n",
    "        fig, axs = plt.subplots( 2, 3, figsize=(12, 6), layout='constrained', dpi = 300 )\n",
    "        for i, SR in enumerate(variances['SR'].unique()):\n",
    "            ax = axs.flatten()[i]\n",
    "            i1 = variances['SR'] == SR\n",
    "            i2 = variances['name'] == name\n",
    "            tmp = variances[ i1 & i2 ]\n",
    "            for column in tmp.columns[3:]:\n",
    "                ax.plot(tmp['rho'], np.sqrt(tmp[column]), label=column)\n",
    "            #ax.axhline( 0, linewidth = 1, color = 'black', linestyle = ':' )\n",
    "            ax.set_ylim( 0, np.sqrt( variances[i2].iloc[:,3:].max().max() ) * 1.05 )\n",
    "            if i == 0: \n",
    "                #legend_thick(ax)\n",
    "                handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.set_xlabel('Autocorrelation')\n",
    "            ax.set_ylabel('Standard Deviation')\n",
    "            ax.set_title(f'SR={SR:.2f}')\n",
    "        remove_empty_axes(axs)\n",
    "        \n",
    "        ax = axs.flatten()[-1]\n",
    "        legend_thick( ax, handles, labels, loc = 'center' )\n",
    "\n",
    "        fig.suptitle( f\"Standard deviation of the Sharpe ratio (distribution={name}, T={T})\")\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
